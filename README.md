# AI Storybook - Flutter App

Egy gyerekeknek sz√≥l√≥ AI mesegener√°tor alkalmaz√°s, amely **Ollama** seg√≠ts√©g√©vel k√©sz√≠t egyedi mes√©ket lok√°lisan, internetkapcsolat n√©lk√ºl!

## üöÄ Funkci√≥k

- **Lok√°lis AI Mese Gener√°l√°s**: Ollama AI modellek √°ltal gener√°lt egyedi, kreat√≠v mes√©k
- **Automatikus Illusztr√°ci√≥k**: Sz√≠nes placeholder k√©pek minden oldalhoz
- **Interakt√≠v Mesek√∂nyv**: Lapozhat√≥ mese megjelen√≠t√©s
- **Lok√°lis K√∂nyvt√°r**: Mentett mes√©k t√°rol√°sa √©s kezel√©se
- **Keres√©s**: Keres√©s a mentett mes√©k k√∂z√∂tt
- **Gyerekbar√°t UI**: Sz√≠nes, modern Material 3 diz√°jn
- **100% Offline**: Internetkapcsolat n√©lk√ºl m≈±k√∂dik!

## üì± K√©perny≈ëk

1. **F≈ëk√©perny≈ë**: √údv√∂zl≈ë k√©perny≈ë a f≈ë funkci√≥kkal
2. **Mese Gener√°l√°s**: T√©ma bevitel √©s AI gener√°l√°s
3. **Mese Megjelen√≠t√©s**: Lapozhat√≥ mesek√∂nyv n√©zet
4. **K√∂nyvt√°r**: Mentett mes√©k list√°ja √©s kezel√©se

## üõ†Ô∏è Technol√≥giai Stack

- **Flutter**: 3.0+ (null safety)
- **Ollama**: Lok√°lis AI model futtat√°s
- **Hive**: Lok√°lis adatb√°zis
- **PageView**: Lapozhat√≥ mese n√©zet
- **Material 3**: Modern UI diz√°jn

## üìã El≈ëfelt√©telek

- Flutter SDK 3.0.0 vagy √∫jabb
- Dart 3.0.0 vagy √∫jabb
- **Ollama telep√≠tve √©s fut** (l√°sd: [OLLAMA_SETUP.md](OLLAMA_SETUP.md))
- Android Studio / VS Code

## ‚öôÔ∏è Telep√≠t√©s

### 1. Kl√≥noz√°s √©s f√ºgg≈ës√©gek telep√≠t√©se

```bash
git clone <repository-url>
cd ai_storybook
flutter pub get
```

### 2. Ollama telep√≠t√©se √©s be√°ll√≠t√°sa

**Fontos**: Az alkalmaz√°s haszn√°lat√°hoz Ollama-t kell telep√≠teni!

L√°sd a r√©szletes √∫tmutat√≥t: [OLLAMA_SETUP.md](OLLAMA_SETUP.md)

R√∂viden:
```bash
# Ollama telep√≠t√©se
# Windows: https://ollama.ai/download
# macOS/Linux: curl -fsSL https://ollama.ai/install.sh | sh

# Model let√∂lt√©se
ollama pull llama2

# Ollama ind√≠t√°sa
ollama serve
```

### 3. Hive model gener√°l√°s

```bash
flutter packages pub run build_runner build
```

### 4. Alkalmaz√°s futtat√°sa

```bash
flutter run
```

## üîß Konfigur√°ci√≥

### Ollama AI Mese Rendszer

Az alkalmaz√°s a k√∂vetkez≈ë AI funkci√≥kat biztos√≠tja:

- **Lok√°lis AI Modellek**: Ollama seg√≠ts√©g√©vel futtatott modellek
- **Chat API**: Modern chat form√°tum a jobb mese gener√°l√°shoz
- **Teljes Mes√©k**: Folyamatos, oldalakra nem bontott t√∂rt√©netek
- **Sz√∂veges Form√°tum**: Tiszt√°n sz√∂veges mes√©k, k√©p n√©lk√ºl
- **Gyors Gener√°l√°s**: Optimaliz√°lt teljes√≠tm√©ny
- **System Promptok**: Struktur√°lt, gyerekbar√°t mese√≠r√°s
- **Gyerekbar√°t Promptok**: Magyar nyelv≈±, koroszt√°lyhoz igaz√≠tott mes√©k
- **Fallback Rendszer**: Kreat√≠v mes√©k ha az AI nem el√©rhet≈ë
- **Offline M≈±k√∂d√©s**: Internetkapcsolat n√©lk√ºl is m≈±k√∂dik

### Alap√©rtelmezett Be√°ll√≠t√°sok

- **Ollama URL**: `http://127.0.0.1:11434`
- **Alap√©rtelmezett Model**: `llama2`
- **Nyelv**: Magyar
- **C√©lk√∂z√∂ns√©g**: 3-8 √©ves gyerekek

### Model V√°ltoztat√°s

M√°s model haszn√°lat√°hoz szerkeszd a `lib/services/openai_service.dart` f√°jlt:

```dart
// A generateStory met√≥dusban:
'model': 'llama2', // V√°ltoztasd ezt a k√≠v√°nt modellre

// P√©ld√°k:
// 'llama2' - alap√©rtelmezett
// 'llama3.2' - √∫jabb verzi√≥
// 'phi3:3.8b' - gyorsabb, kisebb modell
// 'mistral' - hat√©kony modell
```

## üìñ Haszn√°lat

### 1. √öj mese gener√°l√°sa

1. **Ind√≠tsd el Ollama-t** √©s gy≈ëz≈ëdj meg r√≥la, hogy fut
2. Nyisd meg az alkalmaz√°st
3. Kattints az "√öj mese gener√°l√°sa" gombra
4. √çrd be a mese t√©m√°j√°t (pl. "kiskutya", "macska", "robot")
5. Kattints a "Gener√°l√°s" gombra
6. V√°rj, am√≠g az AI elk√©sz√≠ti a mes√©t

### 2. Mese olvas√°sa

- Haszn√°ld a bal/jobb nyilakat a lapoz√°shoz
- A pontok jelzik az aktu√°lis oldalt
- Minden oldal tartalmazza az illusztr√°ci√≥t √©s a sz√∂veget

### 3. Mese ment√©se

- A mese megjelen√≠t√©se k√∂zben kattints a "Ment√©s a k√∂nyvt√°rba" gombra
- A mese automatikusan ment√©sre ker√ºl a lok√°lis k√∂nyvt√°rba

### 4. K√∂nyvt√°r kezel√©se

- A "K√∂nyvt√°ram" men√ºpontban tal√°lod a mentett mes√©ket
- Keres√©s a mes√©k k√∂z√∂tt
- Egyedi vagy √∂sszes mese t√∂rl√©se
- Kattints egy mes√©re a megnyit√°shoz

## üé® UI/UX Jellemz≈ëk

- **Sz√≠ns√©ma**: K√©k alap√∫ Material 3 diz√°jn
- **Gyerekbar√°t**: Nagy gombok, olvashat√≥ bet≈±t√≠pusok
- **Reszponz√≠v**: K√ºl√∂nb√∂z≈ë k√©perny≈ëm√©retek t√°mogat√°sa
- **Anim√°ci√≥k**: Smooth √°tmenetek √©s loading √°llapotok
- **Hozz√°f√©rhet≈ës√©g**: Vil√°gos kontrasztok √©s olvashat√≥ sz√∂vegek

## üîí Biztons√°g

- **100% Lok√°lis**: Minden adat a saj√°t g√©peden marad
- **Nincs API kulcs**: Ollama lok√°lisan fut
- **Adatv√©delem**: Nincs adatk√ºld√©s harmadik feleknek
- **Offline**: Internetkapcsolat n√©lk√ºl is m≈±k√∂dik

## üêõ Hibaelh√°r√≠t√°s

### Gyakori probl√©m√°k

1. **"Ollama connection failed" hiba**
   - Ellen≈ërizd, hogy Ollama fut-e: `ollama list`
   - Ind√≠tsd √∫jra Ollama-t: `ollama serve`
   - Ellen≈ërizd a port 11434 el√©rhet≈ës√©g√©t

2. **"Model not found" hiba**
   - T√∂ltsd le a modellt: `ollama pull llama2`
   - Ellen≈ërizd a let√∂lt√∂tt modelleket: `ollama list`

3. **Lass√∫ mese gener√°l√°s**
   - Haszn√°lj kisebb modelleket: `ollama pull llama2:7b`
   - Z√°rj be m√°s alkalmaz√°sokat a RAM felszabad√≠t√°s√°hoz

4. **Hive hiba**
   - Futtasd: `flutter packages pub run build_runner build`
   - T√∂r√∂ld az alkalmaz√°st √©s telep√≠tsd √∫jra

### Debug m√≥d

```bash
flutter run --debug
```

## üì± Platform T√°mogat√°s

- ‚úÖ Android (API 21+)
- ‚úÖ iOS (12.0+)
- ‚úÖ Web (Chrome, Firefox, Safari)
- ‚úÖ Desktop (Windows, macOS, Linux)

## ü§ù K√∂zrem≈±k√∂d√©s

1. Fork a projektet
2. Hozz l√©tre egy feature branch-et (`git checkout -b feature/amazing-feature`)
3. Commit a v√°ltoztat√°sokat (`git commit -m 'Add amazing feature'`)
4. Push a branch-et (`git push origin feature/amazing-feature`)
5. Nyiss egy Pull Request-et

## üìÑ Licenc

Ez a projekt MIT licenc alatt van. L√°sd a `LICENSE` f√°jlt r√©szletek√©rt.

## üìû Kapcsolat

Ha k√©rd√©sed van vagy probl√©m√°ba √ºtk√∂z√∂l:
- Nyiss egy Issue-t a GitHub-on
- Vagy √≠rj emailt: pappzoltan.p@gmail.com

## üôè K√∂sz√∂net

- **Ollama csapat** a lok√°lis AI model futtat√°s√©rt
- **Flutter csapat** a remek keretrendszer√©rt
- **Hive csapat** a lok√°lis adatb√°zis megold√°s√©rt

---

**Megjegyz√©s**: Ez az alkalmaz√°s **Ollama**-t haszn√°l, amely ingyenes √©s lok√°lisan fut. Nincs sz√ºks√©g internetkapcsolatra vagy API kulcsokra a mese gener√°l√°shoz!

AI Storybook - Flutter App

A children‚Äôs AI story generator application that creates unique stories locally with Ollama, without an internet connection!

üöÄ Features

Local AI Story Generation: Unique, creative stories generated by Ollama AI models

Automatic Illustrations: Colorful placeholder images for every page

Interactive Storybook: Page-flip story presentation

Local Library: Save and manage generated stories

Search: Find stories in the library

Child-Friendly UI: Colorful, modern Material 3 design

100% Offline: Works without an internet connection!

üì± Screens

Home Screen: Welcome screen with main functions

Story Generation: Enter topic and generate with AI

Story Display: Page-flip storybook view

Library: List and manage saved stories

üõ†Ô∏è Technology Stack

Flutter: 3.0+ (null safety)

Ollama: Local AI model execution

Hive: Local database

PageView: Page-flip story view

Material 3: Modern UI design

üìã Prerequisites

Flutter SDK 3.0.0 or newer

Dart 3.0.0 or newer

Ollama installed and running (see: OLLAMA_SETUP.md
)

Android Studio / VS Code

‚öôÔ∏è Installation
1. Clone and install dependencies
git clone <repository-url>
cd ai_storybook
flutter pub get

2. Install and set up Ollama

Important: You need Ollama installed to use the app!

See the detailed guide: OLLAMA_SETUP.md

Quick start:

# Install Ollama
# Windows: https://ollama.ai/download
# macOS/Linux: curl -fsSL https://ollama.ai/install.sh | sh

# Download model
ollama pull llama2

# Start Ollama
ollama serve

3. Hive model generation
flutter packages pub run build_runner build

4. Run the app
flutter run

üîß Configuration
Ollama AI Story System

The application provides the following AI features:

Local AI Models: Models run locally with Ollama

Chat API: Modern chat format for better story generation

Full Stories: Continuous narratives, not split into pages by default

Text-Only Format: Plain text stories without images

Fast Generation: Optimized performance

System Prompts: Structured, child-friendly storytelling

Child-Friendly Prompts: Hungarian prompts tailored to age groups

Fallback System: Creative backup stories if AI is unavailable

Offline Operation: Works fully without internet access

Default Settings

Ollama URL: http://127.0.0.1:11434

Default Model: llama2

Language: Hungarian

Target Audience: Children aged 3‚Äì8

Changing Models

To use another model, edit the lib/services/openai_service.dart file:

// In the generateStory method:
'model': 'llama2', // Change this to the desired model

// Examples:
// 'llama2' - default
// 'llama3.2' - newer version
// 'phi3:3.8b' - smaller, faster model
// 'mistral' - efficient model

üìñ Usage
1. Generate a new story

Start Ollama and make sure it is running

Open the application

Click on ‚ÄúGenerate New Story‚Äù

Enter a topic (e.g., ‚Äúpuppy‚Äù, ‚Äúcat‚Äù, ‚Äúrobot‚Äù)

Press ‚ÄúGenerate‚Äù

Wait for the AI to create the story

2. Read a story

Use left/right arrows to flip pages

Dots indicate the current page

Each page includes an illustration and text

3. Save a story

While viewing a story, press ‚ÄúSave to Library‚Äù

The story will automatically be saved locally

4. Manage the library

Open ‚ÄúMy Library‚Äù to see saved stories

Search through stories

Delete individual or all stories

Tap on a story to open it

üé® UI/UX Features

Color Scheme: Blue-based Material 3 design

Child-Friendly: Large buttons, readable fonts

Responsive: Supports various screen sizes

Animations: Smooth transitions and loading states

Accessibility: Clear contrasts and readable text

üîí Security

100% Local: All data stays on your device

No API Keys: Ollama runs locally

Data Privacy: No data sent to third parties

Offline: Works without internet access

üêõ Troubleshooting
Common Issues

‚ÄúOllama connection failed‚Äù error

Check if Ollama is running: ollama list

Restart Ollama: ollama serve

Verify port 11434 is available

‚ÄúModel not found‚Äù error

Download model: ollama pull llama2

Check installed models: ollama list

Slow story generation

Use smaller models: ollama pull llama2:7b

Close other applications to free up RAM

Hive error

Run: flutter packages pub run build_runner build

Reinstall the app if needed

Debug mode
flutter run --debug

üì± Platform Support

‚úÖ Android (API 21+)

‚úÖ iOS (12.0+)

‚úÖ Web (Chrome, Firefox, Safari)

‚úÖ Desktop (Windows, macOS, Linux)

ü§ù Contribution

Fork the project

Create a feature branch (git checkout -b feature/amazing-feature)

Commit changes (git commit -m 'Add amazing feature')

Push to branch (git push origin feature/amazing-feature)

Open a Pull Request

üìÑ License

This project is licensed under the MIT License. See the LICENSE file for details.

üìû Contact

If you have questions or issues:

Open an issue on GitHub

Or send an email: pappzoltan.p@gmail.com

üôè Acknowledgements

Ollama team for local AI model execution

Flutter team for the framework

Hive team for the local database solution

Note: This application uses Ollama, which runs locally for free. No internet connection or API keys are required for story generation!

‚úÖ Private: No data sent to third parties

‚úÖ Customizable: You can use any model you want


- ‚úÖ **Priv√°t**: Nincs adatk√ºld√©s harmadik feleknek
- ‚úÖ **Testreszabhat√≥**: B√°rmilyen modellt haszn√°lhatsz
